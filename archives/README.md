## Archive Scripts

<table border="1">
    <tr>
        <th>Projects</th>
        <th>GitHub Link</th>
        <th>Colab Link</th>
        <th>Blog Link</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>Youtube Cloner</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Alchemy-Chamber/tree/main/Projects/YT_Clones">Folder</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Alchemy-Chamber/blob/main/Projects/YT_Clones/Fireship_clone.ipynb">Fireship GPT</a></td>
        <td>Blog coming soon</td>
        <td>An Attempt at cloning youtubers using LLMs by Finetuning</td>
    </tr>
</table>



<table border="1">
    <tr>
        <th>Finetuning</th>
        <th>GitHub Link</th>
        <th>Colab Link</th>
        <th>Blog Link</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>Gemma Finetuning</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Gemma_finetuning_notebook.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Gemma_finetuning_notebook.ipynb">Colab</a></td>
        <td><a href="https://medium.com/@adithyask/a-beginners-guide-to-fine-tuning-gemma-0444d46d821c">A Beginner’s Guide to Fine-Tuning Gemma</a></td>
        <td>Notebook to Finetune Gemma Models</td>
    </tr>
    <tr>
        <td>Mistral-7b Finetuning</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Mistral_finetuning_notebook.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Mistral_finetuning_notebook.ipynb">Colab</a></td>
        <td><a href="https://adithyask.medium.com/a-beginners-guide-to-fine-tuning-mistral-7b-instruct-model-0f39647b20fe">A Beginner’s Guide to Fine-Tuning Mistral 7B Instruct Model</a></td>
        <td>Notebook to Finetune Mistral-7b Model</td>
    </tr>
    <tr>
        <td>Mixtral Finetuning</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Mixtral_finetuning_notebook.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Mixtral_finetuning_notebook.ipynb">Colab</a></td>
        <td><a href="https://generativeai.pub/a-beginners-guide-to-fine-tuning-mixtral-instruct-model-7f6a30aacf61">A Beginner’s Guide to Fine-Tuning Mixtral Instruct Model</a></td>
        <td>Notebook to Finetune Mixtral-7b Models</td>
    </tr>
    <tr>
        <td>LLama2 Finetuning</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Llama2_finetuning_notebook.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Llama2_finetuning_notebook.ipynb">Colab</a></td>
        <td></td>
        <td>Notebook to Finetune Llama2-7b Model</td>
    </tr>
</table>

<table border="1">
    <tr>
        <th>Quantization</th>
        <th>GitHub Link</th>
        <th>Colab Link</th>
        <th>Blog Link</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>AWQ Quantization</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Alchemy-Chamber/blob/main/Quantization/AWQ_Quantization.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Alchemy-Chamber/blob/main/Quantization/AWQ_Quantization.ipynb">Colab</a></td>
        <td><a href="https://adithyask.medium.com/squeeze-every-drop-of-performance-from-your-llm-with-awq-activation-aware-quantization-53973365eaaa?sk=43ddb56748cab819777c1ccad39eb9ee">Squeeze Every Drop of Performance from Your LLM with AWQ</a></td>
        <td>quantise LLM using AWQ.</td>
    </tr>
    <tr>
        <td>GGUF Quantization</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Alchemy-Chamber/blob/main/Quantization/GGUF_Quantization.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Alchemy-Chamber/blob/main/Quantization/GGUF_Quantization.ipynb">Colab</a></td>
        <td><a href="https://adithyask.medium.com/run-any-huggingface-model-locally-6bf817fdaff3?sk=46eea5f41270342bbc513a108fe6e57e">Run any Huggingface model locally</a></td>
        <td>quantise LLM to GGUF formate.</td>
    </tr>
</table>

<table border="1">
    <tr>
        <th>Data Prep</th>
        <th>GitHub Link</th>
        <th>Colab Link</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>Documents -> Dataset</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Cookbook/blob/main/DataPrep/dataset_generator_from_documents.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Cookbook/blob/main/DataPrep/dataset_generator_from_documents.ipynb">Colab</a></td>
        <td>Given Documents generate Instruction/QA dataset for finetuning LLMs</td>
    </tr>
    <tr>
        <td>Topic -> Dataset</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Cookbook/blob/main/DataPrep/dataset_generator_from_topic.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Cookbook/blob/main/DataPrep/dataset_generator_from_topic.ipynb">Colab</a></td>
        <td>Given a Topic generate a dataset to finetune LLMs</td>
    </tr>
    <tr>
        <td>Alpaca Dataset Generation</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Cookbook/blob/main/DataPrep/instruction_dataset_generator.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github.com/adithya-s-k/LLM-Cookbook/blob/main/DataPrep/instruction_dataset_generator.ipynb">Colab</a></td>
        <td>The original implementation of generating instruction dataset followed in the alpaca paper</td>
    </tr>
</table>


## Repo Structure

```
├── DataPrep (Notebook to generate synthetic data)
│   ├── dataset_prep.ipynb
│   └── ...
├── Deployment (TGI/VLLM scripts for testing)
│   └── ...
├── Finetuning (Finalized Finetuning Scripts)
│   ├── Gemma_finetuning_notebook.ipynb
│   ├── Llama2_finetuning_notebook.ipynb
│   ├── Mistral_finetuning_notebook.ipynb
│   ├── Mixtral_finetuning_notebook.ipynb
│   └── ...
├── LLMS (LLM experiments)
│   ├── ambari
│   │   └── ...
│   ├── CodeLLama
│   │   └── ...
│   ├── Gemma
│   │   ├── finetune-gemma.ipynb
│   │   └── gemma-sft.py
│   ├── Llama2
│   │   └── ...
│   ├── Mistral-7b
│   │   └── ...
│   └── Mixtral
│       └── ...
├── Projects (Upcoming ideas to explore)
│   └── YT_Clones
│       ├── Fireship_clone.ipynb
│       ├── youtube_channel_scraper.py
│       └── ...
├── Quantization
│   └── ...
├── utils
│   └── streaming_inference_hf.ipynb
└── RAG (Retrieval Augmented Generation)
    ├── 1_Naive_RAG.ipynb
    ├── 2_Semantic_Chunking_RAG.ipynb
    ├── 3_Sentence_Window_Retrieval_RAG.ipynb
    ├── 4_Auto_Merging_Retrieval_RAG.ipynb
    ├── 5_Agentic_RAG.ipynb
    └── 6_Visual_RAG.ipynb

```

<p align="center">
  <a href="https://adithyask.com">
    <img src="https://api.star-history.com/svg?repos=adithya-s-k/LLM-Alchemy-Chamber&type=Date" alt="Star History Chart">
  </a>
</p>
